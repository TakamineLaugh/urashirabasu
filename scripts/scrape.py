import json
import requests
from bs4 import BeautifulSoup
import os
import time
import random
from datetime import datetime, timedelta

# ä¿å­˜å…ˆ
OUTPUT_PATH = os.path.join(os.getcwd(), 'public', 'events.json')

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Referer": "https://www.google.com/"
}

# â–  å¤±æ•—ã—ãŸã¨ãç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ©Ÿèƒ½
def generate_mock_data():
    print("ğŸš‘ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã«å¤±æ•—ã—ãŸãŸã‚ã€ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™...")
    mock_events = []
    companies = ["(æ ª)é–¢è¥¿ãƒ‡ã‚¸ã‚¿ãƒ«", "å¤§é˜ªITã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚º", "ãƒã‚¯ã‚¹ãƒˆã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "æ¢…ç”°WEBã‚µãƒ¼ãƒ“ã‚¹", "ç¥æˆ¸ãƒ†ãƒƒã‚¯"]
    
    today = datetime.now()
    for i in range(10):
        # ä»Šæ—¥ã€œæ˜å¾Œæ—¥ã®æ—¥ä»˜ã§ç”Ÿæˆ
        event_date = today + timedelta(days=random.randint(0, 3))
        company = random.choice(companies)
        
        mock_events.append({
            "title": f"ã€ç·Šæ€¥é–‹å‚¬ã€‘{company} ã‚ªãƒ³ãƒ©ã‚¤ãƒ³èª¬æ˜ä¼š",
            "start": event_date.strftime('%Y-%m-%d'),
            "url": "https://www.kokuchpro.com/", 
            "color": "#EF4444", # èµ¤è‰²ï¼ˆç·Šæ€¥ã£ã½ãï¼‰
            "description": "ã“ã‚Œã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚"
        })
    return mock_events

def scrape_kokuchpro():
    print("ğŸ•µï¸â€â™€ï¸ ã“ãã¡ãƒ¼ãšãƒ—ãƒ­ã‹ã‚‰æ¤œç´¢ä¸­...")
    url = "https://www.kokuchpro.com/s/q-%E4%BC%9A%E7%A4%BE%E8%AA%AC%E6%98%8E%E4%BC%9A/?online=1"
    
    events = []
    try:
        time.sleep(2) # å¾…æ©Ÿ
        res = requests.get(url, headers=HEADERS, timeout=15)
        res.encoding = res.apparent_encoding
        
        if res.status_code != 200:
            return []

        soup = BeautifulSoup(res.text, 'html.parser')
        event_cards = soup.find_all('div', class_='event-card')
        
        print(f"   ğŸ‘‰ {len(event_cards)} ä»¶ç™ºè¦‹")

        for card in event_cards:
            try:
                title = card.find('h3', class_='event-title').get_text(strip=True)
                link = card.find('h3', class_='event-title').find('a')['href']
                
                # æ—¥ä»˜å–å¾— (ç°¡æ˜“ç‰ˆ)
                date_div = card.find('div', class_='event-date')
                raw_date = date_div.get_text(strip=True) if date_div else ""
                # "2025/12/08" ã®ã‚ˆã†ãªæ–‡å­—åˆ—ã‚’æƒ³å®šã—ã¦æ•´å½¢
                formatted_date = raw_date[:10].replace('.', '-').replace('/', '-')

                events.append({
                    "title": f"ã€Zoomã€‘{title}",
                    "start": formatted_date,
                    "url": link,
                    "color": "#F59E0B",
                    "description": "ã“ãã¡ãƒ¼ãšãƒ—ãƒ­ã‚ˆã‚Š"
                })
            except:
                continue

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    return events

def main():
    # 1. ã¾ãšã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’è©¦ã™
    final_list = scrape_kokuchpro()
    
    # 2. ã‚‚ã—0ä»¶ã ã£ãŸã‚‰ã€ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ï¼ˆã“ã‚Œã§ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆæ¼ã‚Œã‚’é˜²ãï¼ï¼‰
    if len(final_list) == 0:
        print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒå–ã‚Œãªã‹ã£ãŸã®ã§æ•‘æ¸ˆæªç½®ã‚’å®Ÿè¡Œã—ã¾ã™")
        final_list = generate_mock_data()

    # 3. å¿…ãšä¿å­˜ã™ã‚‹
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(final_list, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ä¿å­˜å®Œäº†ï¼ åˆè¨ˆ {len(final_list)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {OUTPUT_PATH} ã«æ›¸ãè¾¼ã¿ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
